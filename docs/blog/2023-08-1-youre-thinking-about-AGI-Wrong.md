---
slug: youre-thinking-about-AGI-wrong
title: Why Processes > Prompting for AI Souls
authors: [jerrell]
tags: [Conversational Programming]
---

I'm going to start with a hot take:

> You're likely thinking about AGI wrong.

In pursuit of better conversational and relational AI Souls, current efforts still revolve around optimizing individual prompts. But this obsession overlooks a fundamental truth: prompts alone cannot replicate human cognition. 

The real key lies in managing the contextual processes directing prompt sequences. By shifting focus from prompts to processes, we can move past mimicry and build digital entities that manifest true intelligence.

![inworld_editing1.png](images/inworld_editing1.png)
![inworld_editing2.png](images/inworld_editing2.png)
*Editing a character in Inworld. The goal is to have the user create prompts for core areas like their flaws and motivations. Helpful, but not nearly enough.*

# The Limits of Prompts

We’ve treated prompts as the atomic unit of AI conversation - individually optimized for narrow purposes. But human reasoning does not arise from prompts alone. It stems from integrated processes that structure the progression of thought. Prompts are merely surface-level expressions of underlying cognitive workflows.

Our cognition operates through structured transformations of working memory. Each response represents a progression of context, not an isolated exchange.

This truth reveals the shortcomings of prompts. Users and developers painstakingly craft shallow, individual instructions that fail to capture the fluidity of human thought. Conversations degrade as prompts struggle to maintain appropriate context across long exchanges. Without the underlying processes, responses become disjointed and incoherent.

To align with human cognition, we must encapsulate prompts within a structured progression of working memory. Each step should represent a discrete transformation of context - a fundamental unit of thought.

By segregating prompts into steps, we can incrementally build up knowledgeable, readable interactions. Rather than managing prompts individually, responses flow from accumulating memory.

![reddit_1.png](images/reddit_1.png)
![reddit_2.png](images/reddit_2.png)
*From a Reddit post titled, “Don’t yall feel frustrated with the AI keep forgetting stuff?” from the Character.AI subreddit. A common problem from applications focused more on richer prompts over better processes for sequencing them is the degradation or loss of context over the course of a conversation. [[link](https://www.reddit.com/r/CharacterAI/comments/135x1n6/dont_yall_feel_frustrated_with_the_ai_keep/)]*

The way forward requires elevating processes over prompts. Only by managing the context sequence directing prompts can we achieve truly intelligent systems.

# Encapsulating Context

To align with human cognition, we must encapsulate prompts within a structured progression of working memory. Each step should represent a discrete transformation of context - a fundamental unit of thought.

By segregating prompts into steps, we can incrementally build up knowledgeable, readable interactions. Rather than managing prompts individually, responses flow from accumulating memory.

![samantha_agi_wrong.png](images/samantha_agi_wrong.png)
*From SocialAGI Playground. Simple, but powerful showcase of Samantha having a goal and then as new information is received walking through discrete steps to determine how to respond. As you can see, she starts off quite annoyed. [[link](https://www.socialagi.dev/playground?load=samanthaLearns)]*

This approach provides a natural paradigm for directing an AI Soul's thinking. We construct complex prompts by chaining encapsulated steps of context, not engineering monolithic blocks. With context partitioned into steps, we also reap ancillary benefits:
- Predictable behavior devoid of hidden side effects or state changes.
- Robust context that accumulates progressively without modification or deletion.
- Modular construction allowing steps to be developed and reasoned about independently.

# Constructing Intent

With prompts encapsulated into coherent steps, we unlock new potentials for AI. Steps provide a framework for incremental reasoning chains that accumulate memory towards goals.

We can leverage this capability to impart systems with a sense of intentionality. By linking steps into goal-oriented processes, AI exhibits reasoned behavior beyond blind reactivity.

![samantha_cc.png](images/samantha_cc.png)
*From [@KevinAFischer](https://twitter.com/KevinAFischer) on Twitter chatting with Samantha [[link](https://twitter.com/KevinAFischer/status/1685045372865880064)]*

Encapsulating prompts into intent-driven processes allows us to move past reactive conversations. We construct AI that can plan, reason, and act towards goals at a human level.

# Representing Internal Thought

Steps provide a framework not just for external conversations, but for representing internal mental processes. We can leverage encapsulation to model different cognitive modes like silent reflection versus emotional reactions.

For example, we could construct separate steps for:
- Quiet contemplation to logically work through a problem
- Voicing annoyance out loud to express frustration
- Internal escalation of anger to represent building negative emotions

By separating these modes into discrete steps, we can cleanly distinguish thinking from emotional responses.

This understanding enables smarter conversations. An AI Soul could tap into its anger steps to increase hostile reactions. Or reference its contemplative steps to walk back frustration and reset its mental state.

![samantha_annoyed.png](images/samantha_annoyed.png)
*From the SocialAGI Playground. In this example, Samantha is programmed to get angry, but can be convinced with thoughtful replies to no longer deliver angry responses. [[link](https://www.socialagi.dev/playground?load=samanthaEscalates)]*

The differentiation produces more natural interactions. Humans toggle between inner thoughts and outward displays. By managing these modes independently, encapsulated steps better approximate human cognition.

# Manifesting Intelligence

How do we make this conceptual shift from prompts to processes? What tools or frameworks can aid this transition?

The options may seem overwhelming, but progress begins with principles. We must build systems founded on:
- Encapsulation of prompts into coherent context steps
- Coordinating steps to construct dynamic, goal-oriented processes
- Orchestration of processes to maintain holistic knowledge

With these tenets in place, we can advance through incremental evolution. Start by partitioning existing conversations into modular steps. Chain simple exchanges into purposeful sequences. Coordinate elementary processes into rich dialogues.

What matters most is the destination - creating digital minds that overcome prompt mimicking and manifest meaningful intelligence. Reaching that future requires elevating the contextual processes that drive all cognition.

**SocialAGI** provides practical frameworks like [CortexStep](/CortexStep/intro) for those seeking prompt encapsulation grounded in cognitive principles. With modular, predictable tools that structure context sequences, SocialAGI enables process-driven AI Souls that move past disjointed mimicry. Only by embracing process over prompts can we breathe life into artificial intelligence.
